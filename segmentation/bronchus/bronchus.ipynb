{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "base_url = 'http://10.55.72.205:8000'\n",
    "base_url = 'http://localhost:8001'\n",
    "api_key = '8f3aec8e-b1e4-4967-8fc9-3b073edf0e89'\n",
    "api_key = '1800f748-a688-49c3-ad00-f660d40fd2e3'\n",
    "algorithm_name = 'Bronchus Segmentation'\n",
    "api_dicom_location = '{0}/api/dicomlocation'.format(base_url)\n",
    "api_dataset = '{0}/api/dataset'.format(base_url)\n",
    "api_dataset_ready = '{0}/api/dataset/ready'.format(base_url)\n",
    "api_data_object = '{0}/api/dataobject'.format(base_url)\n",
    "api_trigger = '{0}/api/trigger'.format(base_url)\n",
    "api_algorithm = '{0}/api/algorithm'.format(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Orthanc Location\n",
      "{'ae_title': 'ORTHANC',\n",
      " 'host': '127.0.0.1',\n",
      " 'id': 1,\n",
      " 'name': 'Orthanc',\n",
      " 'owner_key': '1800f748-a688-49c3-ad00-f660d40fd2e3',\n",
      " 'port': 4242}\n"
     ]
    }
   ],
   "source": [
    "# Check if we already have the Orthanc Dicom Location, if not lets add it\n",
    "orthanc_location = None\n",
    "r = requests.get(api_dicom_location, headers={'API_KEY': api_key})\n",
    "for d in r.json():\n",
    "    if d['name'] == 'Orthanc':\n",
    "        orthanc_location = d\n",
    "        break\n",
    "        \n",
    "if not orthanc_location:\n",
    "    # If we didn't find the Orthanc location then lets add it now\n",
    "    data = {'name': 'Orthanc',\n",
    "           'host': '127.0.0.1',\n",
    "           'port': 4242,\n",
    "           'ae_title': 'ORTHANC',\n",
    "           'move_ae_title': 'LOCALDICOM',\n",
    "           'move_port': 7778}\n",
    "    r = requests.post(api_dicom_location, headers={'API_KEY': api_key}, data=data)\n",
    "    \n",
    "    if r.status_code >= 200 and r.status_code < 300:\n",
    "        print('Added Orthanc Location')\n",
    "        orthanc_location = r.json()\n",
    "        \n",
    "pprint(orthanc_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Dataset\n",
      "{'from_dicom_location': {'ae_title': 'ORTHANC',\n",
      "                         'host': '127.0.0.1',\n",
      "                         'id': 1,\n",
      "                         'name': 'Orthanc',\n",
      "                         'owner_key': '1800f748-a688-49c3-ad00-f660d40fd2e3',\n",
      "                         'port': 4242},\n",
      " 'from_dicom_location_id': 1,\n",
      " 'id': 1,\n",
      " 'input_data_objects': [],\n",
      " 'output_data_objects': [],\n",
      " 'owner_key': '1800f748-a688-49c3-ad00-f660d40fd2e3',\n",
      " 'timeout': '2019-05-10T03:45:24.604',\n",
      " 'timestamp': '2019-05-09T03:45:24.613',\n",
      " 'to_dicom_location': None,\n",
      " 'to_dicom_location_id': None}\n"
     ]
    }
   ],
   "source": [
    "# Create a new Dataset\n",
    "data = {'from_dicom_location': orthanc_location['id']}\n",
    "dataset = None\n",
    "r = requests.post(api_dataset, headers={'API_KEY': api_key}, data=data)\n",
    "if r.status_code >= 200 and r.status_code < 300:\n",
    "        print('Added Dataset')\n",
    "        dataset = r.json()\n",
    "        \n",
    "pprint(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Data Object\n",
      "{'children': [],\n",
      " 'dataset_id': 1,\n",
      " 'id': 3,\n",
      " 'is_fetched': False,\n",
      " 'is_input': True,\n",
      " 'is_sent': False,\n",
      " 'meta_data': None,\n",
      " 'parent': None,\n",
      " 'parent_id': None,\n",
      " 'path': None,\n",
      " 'series_instance_uid': '2.16.840.1.114362.1.11775105.22396782581.502959996.669.2',\n",
      " 'status': None,\n",
      " 'timestamp': '2019-05-09T03:46:31.676',\n",
      " 'type': 'DICOM'}\n"
     ]
    }
   ],
   "source": [
    "# Add a Dicom file to the dataset\n",
    "# Create a new Dataset\n",
    "data = {'dataset': dataset['id'],\n",
    "       'type': 'DICOM',\n",
    "       'dicom_retrieve': 'MOVE',\n",
    "       'seriesUID': '2.16.840.1.114362.1.11775105.22396782581.502959996.669.2'}\n",
    "data_object = None\n",
    "r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data)\n",
    "if r.status_code >= 200 and r.status_code < 300:\n",
    "        print('Added Data Object')\n",
    "        data_object = r.json()\n",
    "        \n",
    "pprint(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bronchus Segmentation', 'default_settings': {'contours': [], 'radiomics': {}, 'pyradiomics_settings': {'binWidth': 25, 'resampledPixelSpacing': None, 'interpolator': 'sitkNearestNeighbor', 'verbose': True, 'removeOutliers': 10000}, 'resample_to_image': False, 'append_histogram': False, 'histogram_bins': 256}}\n"
     ]
    }
   ],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        if algorithm_name in a['name']:\n",
    "            algorithm = a\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Error': 'Dataset contains Data Objects that have not been fetched yet. Wait for them to be fetched or DICOM Send them if necessary.'}\n",
      "Algorithm Processing Complete\n"
     ]
    }
   ],
   "source": [
    "# Trigger the algorithm with our dataset containing the data object\n",
    "data={'dataset': dataset['id'],\n",
    "     'algorithm': algorithm['name']}\n",
    "r = requests.post(api_trigger, headers={'API_KEY': api_key}, data=data)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # Poll the URL given to determine the progress of the task\n",
    "    poll_url = '{0}{1}'.format(base_url, r.json()['poll'])\n",
    "    \n",
    "    while(1):\n",
    "        r = requests.get(poll_url, headers={'API_KEY': api_key})\n",
    "        status = r.json()\n",
    "        print(status)\n",
    "\n",
    "        if status['state'] == 'SUCCESS' or status['state'] == 'FAILURE':\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(r.json())\n",
    "    \n",
    "print('Algorithm Processing Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from_dicom_location': {'ae_title': 'ORTHANC',\n",
      "                         'host': '127.0.0.1',\n",
      "                         'id': 2,\n",
      "                         'move_ae_title': 'LOCALDICOM',\n",
      "                         'move_port': 7778,\n",
      "                         'name': 'Orthanc',\n",
      "                         'owner_key': '8f3aec8e-b1e4-4967-8fc9-3b073edf0e89',\n",
      "                         'port': 4242,\n",
      "                         'query': None,\n",
      "                         'query_class': None},\n",
      " 'from_dicom_location_id': 2,\n",
      " 'id': 44,\n",
      " 'input_data_objects': [{'dataset': None,\n",
      "                         'dataset_id': 44,\n",
      "                         'id': 123,\n",
      "                         'is_fetched': True,\n",
      "                         'is_input': True,\n",
      "                         'is_sent': False,\n",
      "                         'meta_data': None,\n",
      "                         'parent': None,\n",
      "                         'parent_id': None,\n",
      "                         'path': '/tmp/tmpl6jumgup/2.16.840.1.114362.1.11775105.22396782581.502959996.669.2',\n",
      "                         'query': None,\n",
      "                         'query_class': None,\n",
      "                         'series_instance_uid': '2.16.840.1.114362.1.11775105.22396782581.502959996.669.2',\n",
      "                         'timestamp': '2019-03-14T04:28:35.702',\n",
      "                         'type': 'DICOM'}],\n",
      " 'output_data_objects': [],\n",
      " 'owner_key': '8f3aec8e-b1e4-4967-8fc9-3b073edf0e89',\n",
      " 'query': None,\n",
      " 'query_class': None,\n",
      " 'timeout': '2019-03-15T04:28:34.555',\n",
      " 'timestamp': '2019-03-14T04:28:34.565',\n",
      " 'to_dicom_location': None,\n",
      " 'to_dicom_location_id': None}\n"
     ]
    }
   ],
   "source": [
    "# Fetch the latest dataset to see the output objects and download the Nifti file!\n",
    "r = requests.get('{0}/{1}'.format(api_dataset, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    dataset = r.json()\n",
    "    pprint(dataset)\n",
    "\n",
    "    for d in dataset['output_data_objects']:\n",
    "        if d['path'].endswith('nii.gz'):\n",
    "            #print(d)\n",
    "            r = requests.get('http://localhost:8000/api/dataobject/download/{0}'.format(d['id']), headers={'API_KEY': api_key})\n",
    "            filename = r.headers['Content-Disposition'].split('filename=')[1]\n",
    "            print('Downloading to: {0}'.format(filename))\n",
    "            open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ready': True}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('{0}/{1}'.format(api_dataset_ready, dataset['id']), headers={'API_KEY': api_key})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
